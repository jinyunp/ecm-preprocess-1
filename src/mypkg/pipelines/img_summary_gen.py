#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import os
import sys
from typing import Any, Dict, List

from PIL import Image
import torch
from transformers import AutoProcessor, AutoModelForVision2Seq

# ---------------- Qwen2-VL ì„¤ì • ----------------

# ì›í•˜ëŠ” Qwen2-VL ëª¨ë¸ ì´ë¦„ (í•„ìš”ì‹œ ë³€ê²½)
MODEL_NAME = "/workspace/qwen" #"Qwen/Qwen2-VL-7B-Instruct"

# í•œ ì¤„ ìš”ì•½ í”„ë¡¬í”„íŠ¸
SUMMARY_PROMPT = (
    "You see a screenshot or UI image from ECMiner data mining software. "
    "In concise English sentence (max 25 words), summarize the main purpose and content of this screen."
    "Explan exactly what the image means. According to whether ii's a screenshot, icon, diagram, etc"
)

print(f"[INFO] Loading model: {MODEL_NAME}")
device = "cuda" if torch.cuda.is_available() else "cpu"
model = AutoModelForVision2Seq.from_pretrained(
    MODEL_NAME,
    torch_dtype="auto",
    device_map="auto" if device == "cuda" else None,
)
processor = AutoProcessor.from_pretrained(MODEL_NAME)
print(f"[INFO] Model loaded on device: {device}")

def clean_qwen_output(raw: str) -> str:
    """
    Qwen ì¶œë ¥ì—ì„œ system/user/assistant í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ì„ ì œê±°í•˜ê³ 
    ë§ˆì§€ë§‰ assistant ì‘ë‹µ ë¬¸ì¥ë§Œ ë‚¨ê¸´ë‹¤.
    ì˜ˆ:
      "system\\n...\\nuser\\n...\\nassistant\\nì‹¤ì œ ìš”ì•½ë¬¸"
      -> "ì‹¤ì œ ìš”ì•½ë¬¸"
    """
    text = (raw or "").strip()

    # ê°€ì¥ ë§ˆì§€ë§‰ 'assistant\n' ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ì„œ ê·¸ ë’¤ë§Œ ì‚¬ìš©
    for sep in ["\nassistant\n", "assistant\n", "assistant:"]:
        if sep in text:
            text = text.split(sep, 1)[1].strip()
    return text


def summarize_image_with_qwen(image_path: str) -> str:
    """
    ë¡œì»¬ Qwen2-VL Instruct ëª¨ë¸ì„ ì´ìš©í•´ ì´ë¯¸ì§€ í•œ ì¥ì„
    í•œ ì¤„ ì˜ì–´ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½.
    """
    try:
        image = Image.open(image_path).convert("RGB")
    except Exception as e:
        print(f"[WARN] Failed to open image {image_path}: {e}", file=sys.stderr)
        return ""

    # Qwen2-VL InstructëŠ” messages + apply_chat_template ë°©ì‹ì´ ê°€ì¥ ì•ˆì „í•¨
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": SUMMARY_PROMPT},
                {"type": "image"},  # ğŸ”´ ì—¬ê¸°ì„œ ì´ë¯¸ì§€ í† í° ìë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì¡ì•„ì¤Œ
            ],
        }
    ]

    # chat template ì ìš© â†’ ë‚´ë¶€ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ í† í°ì„ ì‚½ì…
    chat_text = processor.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
    )

    inputs = processor(
        text=[chat_text],
        images=[image],
        return_tensors="pt",
    ).to(model.device)

    with torch.no_grad():
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=64,
            do_sample=False,
        )

    raw_output = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    cleaned = clean_qwen_output(raw_output)
    return cleaned

# ---------------- ê²½ë¡œ ì²˜ë¦¬ ----------------

def get_chunked_output_path_for_images(sanitized_json_path: str) -> str:
    """
    ì…ë ¥:  .../_sanitized/1ì¥_v3.1_sanitized.json
    ì¶œë ¥: .../_chunked/1ì¥_v3.1_image_llm.json
    """
    dirpath, filename = os.path.split(sanitized_json_path)
    name, ext = os.path.splitext(filename)

    # íŒŒì¼ëª…ì—ì„œ _sanitized ì œê±°
    if name.endswith("_sanitized"):
        base_name = name[: -len("_sanitized")]
    else:
        base_name = name

    out_filename = base_name + "_image_llm" + ext

    parent_dir, last_dir = os.path.split(dirpath)
    if last_dir == "_sanitized":
        out_dir = os.path.join(parent_dir, "_chunked")
    else:
        # fallback: ê°™ì€ ë””ë ‰í„°ë¦¬
        out_dir = dirpath

    os.makedirs(out_dir, exist_ok=True)
    return os.path.join(out_dir, out_filename)


# ---------------- ë©”ì¸ ë¡œì§ ----------------

def process_inline_images_to_chunked(input_path: str) -> str:
    """
    sanitized jsonì—ì„œ inline_images ì •ë³´ë§Œ ì½ê³ ,
    ê° PNG ì´ë¯¸ì§€ì— ëŒ€í•´ llm_text ìƒì„± í›„,
    _chunked í´ë”ì— ì´ë¯¸ì§€ ìš”ì•½ ì „ìš© JSONì„ ì €ì¥í•œë‹¤.
    (ê¸°ì¡´ sanitized jsonì€ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)

    - íŒŒì¼ í™•ì¥ìê°€ .bin ì¸ ê²½ìš°: summary ìŠ¤í‚µ
    - ì§„í–‰ ìƒí™©: [INFO] (i/total_png) í˜•íƒœë¡œ ì¶œë ¥
    """
    with open(input_path, "r", encoding="utf-8") as f:
        doc: Dict[str, Any] = json.load(f)

    inline_images: List[Dict[str, Any]] = doc.get("inline_images", [])

    # sanitized json ê¸°ì¤€ìœ¼ë¡œ _assets ë””ë ‰í„°ë¦¬ ê³„ì‚°
    json_dir = os.path.dirname(input_path)                # .../_sanitized
    assets_dir = os.path.join(json_dir, "_assets")        # .../_sanitized/_assets

    results: List[Dict[str, Any]] = []

    # --- 1) ë¨¼ì € ìš”ì•½ ëŒ€ìƒ PNG ì´ë¯¸ì§€ ëª©ë¡ë§Œ ë½‘ì•„ì„œ total ê³„ì‚° ---
    candidates: List[Tuple[Dict[str, Any], str]] = []

    for img in inline_images:
        original_saved_path = img.get("saved_path") or ""
        filename = img.get("filename")

        # íŒŒì¼ëª… ê²°ì • (filename ìš°ì„ , ì—†ìœ¼ë©´ saved_pathì—ì„œ basename)
        filename_only = filename or os.path.basename(original_saved_path)
        if not filename_only:
            print(f"[WARN] No valid filename for image rId={img.get('rId')}", file=sys.stderr)
            continue

        ext = os.path.splitext(filename_only)[1].lower()

        # 1) .bin íŒŒì¼ì€ ìš”ì•½ ìŠ¤í‚µ
        if ext == ".bin":
            print(f"[INFO] Skipping .bin file for rId={img.get('rId')}: {filename_only}")
            continue

        # 2) PNG ë§Œ ìš”ì•½ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš© (.png ì™¸ í™•ì¥ìëŠ” ìŠ¤í‚µ)
        if ext != ".png":
            print(f"[INFO] Skipping non-PNG image for rId={img.get('rId')}: {filename_only}")
            continue

        candidates.append((img, filename_only))

    total_png = len(candidates)
    print(f"[INFO] Total PNG images to summarize: {total_png}")

    # --- 2) ì‹¤ì œ ìš”ì•½ ì²˜ë¦¬ ë£¨í”„ (ì§„í–‰ë„ ì¶œë ¥ í¬í•¨) ---
    for idx, (img, filename_only) in enumerate(candidates, start=1):
        rId = img.get("rId")
        full_image_path = os.path.join(assets_dir, filename_only)

        if not os.path.exists(full_image_path):
            print(f"[WARN] Image file not found at: {full_image_path}", file=sys.stderr)
            continue

        print(f"[INFO] ({idx}/{total_png}) Summarizing image: rId={rId}, path={full_image_path}")
        summary = summarize_image_with_qwen(full_image_path)

        results.append(
            {
                "rId": rId,
                "filename": filename_only,
                "saved_path": full_image_path,
                "llm_text": summary,
            }
        )

    output_path = get_chunked_output_path_for_images(input_path)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"[INFO] Saved image LLM summaries to {output_path}")
    return output_path


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python summarize_images_with_qwen.py <sanitized_json_path>")
        sys.exit(1)

    input_json = sys.argv[1]
    process_inline_images_to_chunked(input_json)

#python img_summary_gen.py /root/ecm-preprocess-1/output/processed/1ì¥_v3.1/v0/_sanitized/1ì¥_v3.1_sanitized.json
